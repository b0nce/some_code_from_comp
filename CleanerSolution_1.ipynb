{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import matplotlib.pyplot as plt\n",
    "from hashlib import sha1\n",
    "from collections import defaultdict\n",
    "from category_encoders import LeaveOneOutEncoder, CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr = pd.read_csv('../data_orig/Train.csv')\n",
    "dfts = pd.read_csv('../data_orig/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "sha1_hashes = defaultdict(lambda: -1, {sha1(str(i).encode('utf-8')).hexdigest(): i for i in range(10000000)})\n",
    "dftr['user_id_int'] = dftr['user_id'].map(sha1_hashes)\n",
    "dfts['user_id_int'] = dfts['user_id'].map(sha1_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['CHURN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CatBoostEncoder(return_df=True)\n",
    "dftr[['REGION', 'TENURE', 'MRG', 'TOP_PACK']] = encoder.fit_transform(dftr[['REGION', 'TENURE', 'MRG', 'TOP_PACK']], dftr[target])\n",
    "dfts[['REGION', 'TENURE', 'MRG', 'TOP_PACK']] = encoder.transform(dfts[['REGION', 'TENURE', 'MRG', 'TOP_PACK']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "montant_median = np.median(dftr[~dftr['MONTANT'].isna()]['MONTANT'])\n",
    "freq_rech_median = np.median(dftr[~dftr['FREQUENCE_RECH'].isna()]['FREQUENCE_RECH'])\n",
    "rev_median = np.median(dftr[~dftr['REVENUE'].isna()]['REVENUE'])\n",
    "arpu_median = np.median(dftr[~dftr['ARPU_SEGMENT'].isna()]['ARPU_SEGMENT'])\n",
    "freq_median = np.median(dftr[~dftr['FREQUENCE'].isna()]['FREQUENCE'])\n",
    "dvolume_median = np.median(dftr[~dftr['DATA_VOLUME'].isna()]['DATA_VOLUME'])\n",
    "net_median = np.median(dftr[~dftr['ON_NET'].isna()]['ON_NET'])\n",
    "orange_median = np.median(dftr[~dftr['ORANGE'].isna()]['ORANGE'])\n",
    "tigo_median = np.median(dftr[~dftr['TIGO'].isna()]['TIGO'])\n",
    "z1_median = np.median(dftr[~dftr['ZONE1'].isna()]['ZONE1'])\n",
    "z2_median = np.median(dftr[~dftr['ZONE2'].isna()]['ZONE2'])\n",
    "freq_top_median = np.median(dftr[~dftr['FREQ_TOP_PACK'].isna()]['FREQ_TOP_PACK'])\n",
    "\n",
    "dftr['MONTANT'].fillna((montant_median), inplace=True)\n",
    "dftr['FREQUENCE_RECH'].fillna((freq_rech_median), inplace=True)\n",
    "dftr['REVENUE'].fillna((rev_median), inplace=True)\n",
    "dftr['ARPU_SEGMENT'].fillna((arpu_median), inplace=True)\n",
    "dftr['FREQUENCE'].fillna((freq_median), inplace=True)\n",
    "dftr['DATA_VOLUME'].fillna((dvolume_median), inplace=True)\n",
    "dftr['ON_NET'].fillna((net_median), inplace=True)\n",
    "dftr['ORANGE'].fillna((orange_median), inplace=True)\n",
    "dftr['TIGO'].fillna((tigo_median), inplace=True)\n",
    "dftr['ZONE1'].fillna((z1_median), inplace=True)\n",
    "dftr['ZONE2'].fillna((z2_median), inplace=True)\n",
    "dftr['FREQ_TOP_PACK'].fillna((freq_top_median), inplace=True)\n",
    "\n",
    "dfts['MONTANT'].fillna((montant_median), inplace=True)\n",
    "dfts['FREQUENCE_RECH'].fillna((freq_rech_median), inplace=True)\n",
    "dfts['REVENUE'].fillna((rev_median), inplace=True)\n",
    "dfts['ARPU_SEGMENT'].fillna((arpu_median), inplace=True)\n",
    "dfts['FREQUENCE'].fillna((freq_median), inplace=True)\n",
    "dfts['DATA_VOLUME'].fillna((dvolume_median), inplace=True)\n",
    "dfts['ON_NET'].fillna((net_median), inplace=True)\n",
    "dfts['ORANGE'].fillna((orange_median), inplace=True)\n",
    "dfts['TIGO'].fillna((tigo_median), inplace=True)\n",
    "dfts['ZONE1'].fillna((z1_median), inplace=True)\n",
    "dfts['ZONE2'].fillna((z2_median), inplace=True)\n",
    "dfts['FREQ_TOP_PACK'].fillna((freq_top_median), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "    'REGION', 'TENURE', 'MONTANT', 'FREQUENCE_RECH', 'REVENUE',\n",
    "    'ARPU_SEGMENT', 'FREQUENCE', 'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO',\n",
    "    'ZONE1', 'ZONE2', 'MRG', 'REGULARITY', 'TOP_PACK', 'FREQ_TOP_PACK', 'user_id_int'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_for_check = np.linspace(0, 2000, 100000)\n",
    "def get_half_window_len(std, eps=1e-6):\n",
    "    return int(np.round(space_for_check[np.argwhere(stats.norm.pdf(space_for_check, loc=0, scale=std) < eps)[0, 0]]))\n",
    "\n",
    "def get_smoothed_value2(a, v, std):\n",
    "    return np.sum(stats.norm.pdf(a - v, loc=0, scale=std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "trw = np.argwhere(dftr[target].values[np.argsort(dftr['user_id_int'])])[:, 0]\n",
    "trw2 = np.concatenate([-trw[trw < wsize], trw, wsize + trw[trw > max(trw) - wsize]])\n",
    "std = 200\n",
    "wsize = get_half_window_len(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_vals_dftr = Parallel(n_jobs=-1)(\n",
    "    delayed(\n",
    "        lambda i: get_smoothed_value2(trw2[(trw2 >= i - wsize) & (trw2 <= i + wsize)], i, std)\n",
    "    )(v) for v in np.arange(max(dftr.user_id_int))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = {i: v for i, v in enumerate(smoothed_vals_dftr)}\n",
    "dftr['weightned_local_churn'] = dftr['user_id_int'].map(td)\n",
    "dfts['weightned_local_churn'] = dfts['user_id_int'].map(td)\n",
    "del td\n",
    "predictors.append('weightned_local_churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbt = lgb.LGBMClassifier(n_estimators=500, boosting_type='dart', class_weight='balanced', colsample_bytree=0.8, subsample=0.8, reg_alpha=0.1, reg_lambda=0.1, learning_rate=0.05)\n",
    "lgbt.fit(dftr[predictors], dftr[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_preds = lgbt.predict_proba(dfts[predictors])[:, 0]  # hide score\n",
    "sub1 = pd.DataFrame({'user_id': dfts['user_id'], 'CHURN': ts_preds})\n",
    "sub1.to_csv('../submissions/hard_dart_weightned_local_churn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
